{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google Application Credentials set to: c:\\Users\\sacha\\FORK\\AI_Final\\projet-integration-au-2024-81640cb2db70.json\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import bigquery\n",
    "import time\n",
    "import os\n",
    "\n",
    "# Get the current working directory in a Jupyter notebook\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# Create the full path\n",
    "key_path = os.path.join(current_dir, 'projet-integration-au-2024-81640cb2db70.json')\n",
    "\n",
    "# Set the environment variable to the path of your JSON key file\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = key_path\n",
    "\n",
    "print(f\"Google Application Credentials set to: {os.environ['GOOGLE_APPLICATION_CREDENTIALS']}\")\n",
    "\n",
    "# Initialiser le client BigQuery\n",
    "client = bigquery.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your dataset and table IDs\n",
    "dataset_id = 'sacha_phishing_url_website'\n",
    "table_id_stagging = \"sacha_table_initial_stagging\"\n",
    "table_id_stagging_na_string = \"sacha_table_initial_stagging_NA_string\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to execute a query and log timing\n",
    "def run_query_with_logging(query, model_name):\n",
    "    start_time = time.time()\n",
    "    print(f\"Training started for {model_name}...\")\n",
    "    \n",
    "    query_job = client.query(query)\n",
    "    query_job.result()  # Wait for the query to complete\n",
    "    \n",
    "    end_time = time.time()\n",
    "    print(f\"Training completed for {model_name} in {end_time - start_time:.2f} seconds.\")\n",
    "\n",
    "# Fetch and print model information after training\n",
    "def get_model_info(model_name):\n",
    "    print(f\"Fetching model details for {model_name}...\")\n",
    "    query = f\"\"\"\n",
    "    SELECT\n",
    "      *\n",
    "    FROM\n",
    "      ML.TRAINING_INFO(MODEL `{dataset_id}.{model_name}`)\n",
    "    \"\"\"\n",
    "    query_job = client.query(query)\n",
    "    results = query_job.result()\n",
    "\n",
    "    print(f\"Training information for {model_name}:\")\n",
    "    for row in results:\n",
    "        print(row)\n",
    "\n",
    "# Helper function to evaluate the trained model\n",
    "def evaluate_model(model_name):\n",
    "    print(f\"Evaluating {model_name}...\")\n",
    "    \n",
    "    # Use ML.EVALUATE to evaluate the model on the entire dataset\n",
    "    query = f\"\"\"\n",
    "    SELECT\n",
    "      *\n",
    "    FROM\n",
    "      ML.EVALUATE(\n",
    "        MODEL `{dataset_id}.{model_name}`,\n",
    "        (SELECT * FROM `{dataset_id}.{table_id_stagging_na_string}`)\n",
    "      )\n",
    "    \"\"\"\n",
    "    \n",
    "    query_job = client.query(query)\n",
    "    results = query_job.result()\n",
    "\n",
    "    print(f\"Evaluation results for {model_name}:\")\n",
    "    for row in results:\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train logistic regression model\n",
    "def train_logistic_regression():\n",
    "    query = f\"\"\"\n",
    "    CREATE OR REPLACE MODEL `{dataset_id}.logistic_regression_model`\n",
    "    OPTIONS(\n",
    "        model_type = 'logistic_reg',\n",
    "        auto_class_weights = TRUE,\n",
    "        max_iterations = 10,  -- Minimal number of iterations for testing\n",
    "        data_split_method = 'RANDOM',  -- Automatically split the data\n",
    "        data_split_eval_fraction = 0.3  -- Use 30% of the data for evaluation\n",
    "    ) AS\n",
    "    SELECT * FROM `{dataset_id}.{table_id_stagging_na_string}`\n",
    "    \"\"\"\n",
    "    run_query_with_logging(query, \"logistic_regression_model\")\n",
    "    print(\"Logistic Regression model trained\")\n",
    "\n",
    "\n",
    "# Train DNN classifier model\n",
    "def train_dnn_classifier():\n",
    "    query = f\"\"\"\n",
    "    CREATE OR REPLACE MODEL `{dataset_id}.dnn_classifier_model`\n",
    "    OPTIONS(\n",
    "        model_type = 'dnn_classifier',\n",
    "        hidden_units = [32],  -- Minimal number of hidden units\n",
    "        max_iterations = 10,  -- Minimal number of iterations for testing\n",
    "        data_split_method = 'RANDOM',  -- Automatically split the data\n",
    "        data_split_eval_fraction = 0.3  -- Use 30% of the data for evaluation\n",
    "    ) AS\n",
    "    SELECT * FROM `{dataset_id}.{table_id_stagging_na_string}`\n",
    "    \"\"\"\n",
    "    run_query_with_logging(query, \"dnn_classifier_model\")\n",
    "    print(\"DNN Classifier model trained\")\n",
    "\n",
    "\n",
    "# Train Decision Tree model\n",
    "def train_decision_tree():\n",
    "    query = f\"\"\"\n",
    "    CREATE OR REPLACE MODEL `{dataset_id}.decision_tree_model`\n",
    "    OPTIONS(\n",
    "        model_type = 'boosted_tree_classifier',\n",
    "        max_iterations = 10,  -- Minimal number of iterations\n",
    "        data_split_method = 'RANDOM',  -- Automatically split the data\n",
    "        data_split_eval_fraction = 0.3  -- Use 30% of the data for evaluation\n",
    "    ) AS\n",
    "    SELECT * FROM `{dataset_id}.{table_id_stagging_na_string}`\n",
    "    \"\"\"\n",
    "    run_query_with_logging(query, \"decision_tree_model\")\n",
    "    print(\"Decision Tree model trained\")\n",
    "\n",
    "\n",
    "# Train Random Forest model\n",
    "def train_random_forest():\n",
    "    query = f\"\"\"\n",
    "    CREATE OR REPLACE MODEL `{dataset_id}.random_forest_model`\n",
    "    OPTIONS(\n",
    "        model_type = 'random_forest_classifier',\n",
    "        data_split_method = 'RANDOM',  -- Use RANDOM split for evaluation\n",
    "        data_split_eval_fraction = 0.3  -- Use 30% of the data for evaluation\n",
    "    ) AS\n",
    "    SELECT * FROM `{dataset_id}.{table_id_stagging_na_string}`\n",
    "    \"\"\"\n",
    "    run_query_with_logging(query, \"random_forest_model\")\n",
    "    print(\"Random Forest model trained\")\n",
    "\n",
    "\n",
    "# Train XGBoost classifier model\n",
    "def train_xgboost():\n",
    "    query = f\"\"\"\n",
    "    CREATE OR REPLACE MODEL `{dataset_id}.xgboost_model`\n",
    "    OPTIONS(\n",
    "        model_type = 'boosted_tree_classifier',\n",
    "        max_iterations = 10,  -- Number of boosting rounds\n",
    "        data_split_method = 'RANDOM',  -- Use RANDOM split for evaluation\n",
    "        data_split_eval_fraction = 0.3  -- Use 30% of the data for evaluation\n",
    "    ) AS\n",
    "    SELECT * FROM `{dataset_id}.{table_id_stagging_na_string}`\n",
    "    \"\"\"\n",
    "    run_query_with_logging(query, \"xgboost_model\")\n",
    "    print(\"XGBoost model trained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started for logistic_regression_model...\n",
      "Training completed for logistic_regression_model in 132.55 seconds.\n",
      "Logistic Regression model trained\n",
      "Training started for decision_tree_model...\n",
      "Training completed for decision_tree_model in 298.16 seconds.\n",
      "Decision Tree model trained\n",
      "Training started for random_forest_model...\n",
      "Training completed for random_forest_model in 310.71 seconds.\n",
      "Random Forest model trained\n",
      "Training started for xgboost_model...\n",
      "Training completed for xgboost_model in 177.62 seconds.\n",
      "XGBoost model trained\n",
      "Evaluating logistic_regression_model...\n",
      "Evaluation results for logistic_regression_model:\n",
      "Row((0.9119037685996384, 0.8305100845391508, 0.8596906326997145, 0.8693058478466203, 0.3434720829050217, 0.9244285714285714), {'precision': 0, 'recall': 1, 'accuracy': 2, 'f1_score': 3, 'log_loss': 4, 'roc_auc': 5})\n",
      "Evaluating decision_tree_model...\n",
      "Evaluation results for decision_tree_model:\n",
      "Row((0.9429475265925896, 0.9437909634930184, 0.9363342020760876, 0.9433690565201739, 0.17565064659184162, 0.984032967032967), {'precision': 0, 'recall': 1, 'accuracy': 2, 'f1_score': 3, 'log_loss': 4, 'roc_auc': 5})\n",
      "Evaluating random_forest_model...\n",
      "Evaluation results for random_forest_model:\n",
      "Row((0.9601536170546281, 0.9697147199442738, 0.9603728774361119, 0.9649104843219571, 0.198988351472218, 0.9915824175824176), {'precision': 0, 'recall': 1, 'accuracy': 2, 'f1_score': 3, 'log_loss': 4, 'roc_auc': 5})\n",
      "Evaluating xgboost_model...\n",
      "Evaluation results for xgboost_model:\n",
      "Row((0.9429475265925896, 0.9437909634930184, 0.9363342020760876, 0.9433690565201739, 0.17565064659184162, 0.984032967032967), {'precision': 0, 'recall': 1, 'accuracy': 2, 'f1_score': 3, 'log_loss': 4, 'roc_auc': 5})\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate all models with minimal configurations\n",
    "def run_all_models_and_evaluate():\n",
    "    # Train models with minimal settings\n",
    "    train_logistic_regression()\n",
    "    #train_dnn_classifier()\n",
    "    train_decision_tree()\n",
    "    train_random_forest()\n",
    "    train_xgboost()\n",
    "\n",
    "    # Evaluate models\n",
    "    evaluate_model('logistic_regression_model')\n",
    "    #evaluate_model('dnn_classifier_model')\n",
    "    evaluate_model('decision_tree_model')\n",
    "    evaluate_model('random_forest_model')\n",
    "    evaluate_model('xgboost_model')\n",
    "\n",
    "# Run all models and evaluation\n",
    "run_all_models_and_evaluate()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
